{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10ab72ab0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from tqdm import tdqm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Tumor Files:  1339\n",
      "Number of Training No Tumor Files:  1595\n"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import random \n",
    "import pandas as pd\n",
    "# open method used to open different extension image file\n",
    "TRAIN_DATA_FOLDER = \"data/train\"\n",
    "train_tumor_filenames = os.listdir(f'{TRAIN_DATA_FOLDER}/tumor/')\n",
    "num_train_tumor_files = len(train_tumor_filenames)\n",
    "print(\"Number of Training Tumor Files: \", num_train_tumor_files)\n",
    "\n",
    "train_notumor_filenames = os.listdir(f'{TRAIN_DATA_FOLDER}/notumor/')\n",
    "num_train_notumor_files = len(train_notumor_filenames)\n",
    "print(\"Number of Training No Tumor Files: \", num_train_notumor_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        tumor_dir = os.path.join(root_dir, 'tumor')\n",
    "        non_tumor_dir = os.path.join(root_dir, 'notumor')\n",
    "\n",
    "        for file in os.listdir(tumor_dir):\n",
    "            if file.lower().endswith('.jpg') or file.lower().endswith('.jpeg'):\n",
    "                self.image_paths.append(os.path.join(tumor_dir, file))\n",
    "                self.labels.append(1)\n",
    "\n",
    "        for file in os.listdir(non_tumor_dir):\n",
    "            if file.lower().endswith('.jpg') or file.lower().endswith('.jpeg'):\n",
    "                self.image_paths.append(os.path.join(non_tumor_dir, file))\n",
    "                self.labels.append(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = image.resize(256,256)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MRIDataset object at 0x111437a70>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x11335fce0>\n",
      "<__main__.MRIDataset object at 0x1112d4740>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x1112d47d0>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MyViT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available else \"\")\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mMyViT\u001b[49m((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m255\u001b[39m),n_patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m, n_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,hidden_d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m,n_heads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m,out_d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m N_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     17\u001b[0m LR \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.005\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MyViT' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset = MRIDataset('data/train/', transform=ToTensor())\n",
    "print(train_dataset)\n",
    "train_loader  = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "print(train_loader)\n",
    "\n",
    "test_dataset = MRIDataset('data/test/', transform=ToTensor())\n",
    "print(test_dataset)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "print(test_loader)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available else \"\")\n",
    "model = MyViT((1,255,255),n_patches = 7, n_blocks = 2,hidden_d = 8,n_heads = 2,out_d=10).to(device)\n",
    "\n",
    "\n",
    "N_EPOCHS = 5\n",
    "LR = 0.005\n",
    "\n",
    "# Training Loop\n",
    "optimizer = Adam(model.parameters(),lr = LR)\n",
    "criterion = CrossEntropyLoss()\n",
    "for epoch in trange(N_EPOCHS,desc=\"Training\"):\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader,desc=f\"Epoch{epoch+1} in training\", leave=False):\n",
    "        x,y = batch\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat,y)\n",
    "\n",
    "        train_loss += loss.detach().cpu().item()/len(train_loader)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS} loss: {train_loss:.2f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct,total = 0,0\n",
    "    test_loss = 0.0\n",
    "    for batch in tqdm(test_loader,desc=\"Testing\"):\n",
    "        x,y = batch\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(x,y)\n",
    "        test_loss += loss.detach().cpu().item()/len(test_loader)\n",
    "\n",
    "        correct += torch.sum(torch.argmax(y_hat,dim=1) == y).detach().cpu()\n",
    "        total += len(x)\n",
    "    print(f\"Test loss: {test_loss:.2f}\")\n",
    "    print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_set = MNIST(root='./../datasets', train=True, download=True, transform=ToTensor())\n",
    "\n",
    "# test_set = MNIST(root='./../datasets', train=False, download=True, transform=transform)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TumorDetectionMRI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
